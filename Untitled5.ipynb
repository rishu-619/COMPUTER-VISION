{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoGnHgx48Ilz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "57075e88-6460-496e-cc65-3808e331a9a9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roHGe1519EFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j94t1jJz9N3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dimensions of our images.\n",
        "input_shape=(150,150,3)\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "train_data_dir = '/content/drive/My Drive/Colab Notebooks/train'\n",
        "validation_data_dir = '/content/drive/My Drive/Colab Notebooks/test'\n",
        "nb_train_samples = 245\n",
        "nb_validation_samples = 59\n",
        "epochs = 10\n",
        "batch_size = 16"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE90lVI-9xBS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "56f38675-cf22-452e-876b-c01090431012"
      },
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator=datagen.flow_from_directory(\n",
        "         train_data_dir,\n",
        "         target_size=(img_width,img_height),\n",
        "         batch_size=8,\n",
        "         class_mode='categorical')\n",
        "\n",
        "validation_generator=datagen.flow_from_directory(\n",
        "         validation_data_dir,\n",
        "         target_size=(img_width,img_height),\n",
        "         batch_size=16,\n",
        "         class_mode='categorical')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 242 images belonging to 3 classes.\n",
            "Found 71 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DK2HUAM_f4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO4INcPo_kmB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "1280152b-58d3-40e0-bc6a-18401ecacb41"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 148, 148, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 72, 72, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 72, 72, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 34, 34, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 34, 34, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 18496)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                1183808   \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,212,513\n",
            "Trainable params: 1,212,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cinvUq0G_mAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', # or categorical_crossentropy\n",
        "              optimizer='adam',# or adagrad\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64qclLCK_qJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xh99Y8L_seb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6064875a-39cc-4954-c1e2-78639c45b84e"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "print(train_generator.class_indices)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 242 images belonging to 3 classes.\n",
            "{'jeans': 0, 'sarees': 1, 'trousers': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmFmzZi4_3Ar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "28608f04-a7ad-4b91-ede7-e0a8ec6a9823"
      },
      "source": [
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 71 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNFE_xvA_7_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "f5ec8a05-4786-407a-af97-001ffaf86375"
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 81s 5s/step - loss: -49.3337 - accuracy: 0.2345 - val_loss: -299.8104 - val_accuracy: 0.2708\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 7s 463ms/step - loss: -411.3224 - accuracy: 0.2434 - val_loss: -238.6670 - val_accuracy: 0.4103\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 2s 127ms/step - loss: -5922.8851 - accuracy: 0.2522 - val_loss: -25531.6875 - val_accuracy: 0.3542\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 2s 145ms/step - loss: -58811.1512 - accuracy: 0.2257 - val_loss: 38032.2188 - val_accuracy: 0.4103\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 2s 134ms/step - loss: -260826.1057 - accuracy: 0.2625 - val_loss: -1436513.1250 - val_accuracy: 0.2564\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 2s 135ms/step - loss: -1102890.0094 - accuracy: 0.2124 - val_loss: -733685.0000 - val_accuracy: 0.3542\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 2s 132ms/step - loss: -3797771.4421 - accuracy: 0.2123 - val_loss: -6057818.0000 - val_accuracy: 0.3077\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 2s 137ms/step - loss: -9396453.4578 - accuracy: 0.2699 - val_loss: -7565760.0000 - val_accuracy: 0.3125\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 2s 149ms/step - loss: -19364041.0607 - accuracy: 0.2478 - val_loss: -29409840.0000 - val_accuracy: 0.3333\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 2s 136ms/step - loss: -34366377.7333 - accuracy: 0.2250 - val_loss: 3307424.0000 - val_accuracy: 0.3846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f76901f9a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKXkgQgMN7V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model1.h5')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thRmpGDONxEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PREDICTION\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUyo_vvzN0R-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dimensions of our images\n",
        "img_width, img_height = 150, 150"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fmS1Q05N2dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the model we saved\n",
        "model = load_model('model1.h5')\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9dghGiwOE2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "outputId": "9b5c1831-8794-486c-d65f-9253f2bd4a71"
      },
      "source": [
        "mypath = \"/content/drive/My Drive/predict/\"\n",
        "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "print(onlyfiles)\n",
        "# predicting images\n",
        "jeans_counter = 0 \n",
        "trousers_counter  = 0\n",
        "sarees_counter = 0\n",
        "for file in onlyfiles:\n",
        "    img = image.load_img(mypath+file, target_size=(img_width, img_height))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    \n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict_classes(images, batch_size=10)\n",
        "    classes = [0,1,2]\n",
        "    \n",
        "    if classes == 0:\n",
        "        print(file + \": \" + 'jeans')\n",
        "        jeans_counter += 1\n",
        "        \n",
        "        \n",
        "    elif classes == 1:\n",
        "        print(file + \": \" + 'sarees')\n",
        "        sarees_counter += 1\n",
        "    else:\n",
        "        print(file + \": \" + 'trousers')\n",
        "        trousers_counter += 1\n",
        "print(\"Total jeans :\",jeans_counter)\n",
        "print(\"Total sarees :\",sarees_counter)\n",
        "print(\"Total trousers :\",trousers_counter)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1247.jpg', '1938.jpg', '1788.jpg', '1818.jpg', '1793.jpg', '1792.jpg', '1830.jpg', '1832.jpg', '1876.jpg', '1921.jpg', '1762.jpg', '1775.jpg', '2994.jpg', '2967.jpg', '2987.jpg', '2943.jpg', '2857.jpg', '2911.jpg', '2941.jpg', '2871.jpg', '2763.jpg', '2811.jpg', '2806.jpg', '2816.jpg', '2762.jpg', '2733.jpg', '1931.jpg', '1970.jpg', '1994.jpg', '1939.jpg', '3924.jpg', '3834.jpg', '3814.jpg', '3715.jpg', '3741.jpg', '3739.jpg', '3705.jpg', '3754.jpg', '3841.jpg', '3627.jpg', '3958.jpg', '3973.jpg', '3928.jpg']\n",
            "1247.jpg: trousers\n",
            "1938.jpg: trousers\n",
            "1788.jpg: trousers\n",
            "1818.jpg: trousers\n",
            "1793.jpg: trousers\n",
            "1792.jpg: trousers\n",
            "1830.jpg: trousers\n",
            "1832.jpg: trousers\n",
            "1876.jpg: trousers\n",
            "1921.jpg: trousers\n",
            "1762.jpg: trousers\n",
            "1775.jpg: trousers\n",
            "2994.jpg: trousers\n",
            "2967.jpg: trousers\n",
            "2987.jpg: trousers\n",
            "2943.jpg: trousers\n",
            "2857.jpg: trousers\n",
            "2911.jpg: trousers\n",
            "2941.jpg: trousers\n",
            "2871.jpg: trousers\n",
            "2763.jpg: trousers\n",
            "2811.jpg: trousers\n",
            "2806.jpg: trousers\n",
            "2816.jpg: trousers\n",
            "2762.jpg: trousers\n",
            "2733.jpg: trousers\n",
            "1931.jpg: trousers\n",
            "1970.jpg: trousers\n",
            "1994.jpg: trousers\n",
            "1939.jpg: trousers\n",
            "3924.jpg: trousers\n",
            "3834.jpg: trousers\n",
            "3814.jpg: trousers\n",
            "3715.jpg: trousers\n",
            "3741.jpg: trousers\n",
            "3739.jpg: trousers\n",
            "3705.jpg: trousers\n",
            "3754.jpg: trousers\n",
            "3841.jpg: trousers\n",
            "3627.jpg: trousers\n",
            "3958.jpg: trousers\n",
            "3973.jpg: trousers\n",
            "3928.jpg: trousers\n",
            "Total jeans : 0\n",
            "Total sarees : 0\n",
            "Total trousers : 43\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}